# app.py â€” ì‚°ì—…ìš© ê³µê¸‰ëŸ‰ ì˜ˆì¸¡(ì¶”ì„¸ë¶„ì„)
# â€¢ ë°ì´í„°: ì—°ë„ë³„ ì—‘ì…€ ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ(ë˜ëŠ” Repoì˜ ì‚°ì—…ìš©_*.xlsx ìë™ ë¡œë”©)
# â€¢ ì „ì²˜ë¦¬: 'ìƒí’ˆëª…'ì— 'ì‚°ì—…ìš©' í¬í•¨ í–‰ë§Œ ì‚¬ìš©, ì—…ì¢… ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ ì§€í‘œ(íŒë§¤ëŸ‰/íŒë§¤ê¸ˆì•¡) ì§‘ê³„
# â€¢ ì¢Œì¸¡: í•™ìŠµ ì—°ë„(ë©€í‹°), ì˜ˆì¸¡ êµ¬ê°„(ì‹œì‘ì—°~ì¢…ë£Œì—°)
# â€¢ ì˜ˆì¸¡: OLS / CAGR / Holt / SES
# â€¢ ê²°ê³¼ ìœ ì§€: session_state
# â€¢ ê·¸ë˜í”„/ë‹¤ìš´ë¡œë“œ: ë™ì¼ + ğŸ”ì›ì²œ ì§„ë‹¨(ì—°ë„ í•©ê³„Â·íŒŒì¼ ë¦¬ìŠ¤íŠ¸)

from pathlib import Path
from io import BytesIO
import re
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt

try:
    from statsmodels.tsa.holtwinters import Holt, SimpleExpSmoothing
except Exception:
    Holt = None
    SimpleExpSmoothing = None

from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.chart import BarChart, Reference, LineChart

st.set_page_config(page_title="ì‚°ì—…ìš© ê³µê¸‰ëŸ‰ ì˜ˆì¸¡(ì¶”ì„¸ë¶„ì„)", layout="wide")
st.title("ğŸ­ğŸ“ˆ ì‚°ì—…ìš© ê³µê¸‰ëŸ‰ ì˜ˆì¸¡(ì¶”ì„¸ë¶„ì„)")
st.caption("ì—°ë„ë³„ ì—‘ì…€ ì—…ë¡œë“œ(ì—¬ëŸ¬ ê°œ) ë˜ëŠ” Repo ì¼ê´„ ë¡œë”© â†’ â€˜ì‚°ì—…ìš©â€™ë§Œ í•„í„° â†’ ì—…ì¢…ë³„Â·ì—°ë„ë³„ ì§‘ê³„ â†’ 4ê°€ì§€ ì¶”ì„¸ ì˜ˆì¸¡")

st.markdown("""
### ğŸ“˜ ì˜ˆì¸¡ ë°©ë²• ì„¤ëª…
- **ì„ í˜•ì¶”ì„¸(OLS)** â€” `y_t = a + b t`, ì˜ˆì¸¡ `Å·_{T+h} = a + b (T+h)`
- **CAGR(ë³µë¦¬ì„±ì¥)** â€” `g = (y_T / y_0)^{1/n}-1`, ì˜ˆì¸¡ `Å·_{T+h} = y_T (1+g)^h`
- **Holt(ì§€ìˆ˜í‰í™œÂ·ì¶”ì„¸í˜•)** â€” `Å·_{T+h} = l_T + h b_T`
- **ì§€ìˆ˜í‰í™œ(SES)** â€” `l_t = Î± y_t + (1-Î±) l_{t-1}`, `Å·_{T+h} = l_T`
""")

with st.sidebar:
    st.header("ğŸ“¥ â‘  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
    ups = st.file_uploader("ì—°ë„ë³„ ì—‘ì…€(.xlsx) ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ", type=["xlsx"], accept_multiple_files=True)

    repo_files = sorted([p for p in Path(".").glob("ì‚°ì—…ìš©_*.xlsx")])
    use_repo = st.checkbox(f"Repo íŒŒì¼ ìë™ ì½ê¸° ({len(repo_files)}ê°œ ê°ì§€ë¨)", value=bool(repo_files))
    if repo_files:
        st.write("ì½ì„ ëŒ€ìƒ:", "\n\n".join([f"- {p.name}" for p in repo_files]))

    st.divider()
    st.header("ğŸ¯ â‘¡ ì§‘ê³„ ëŒ€ìƒ(ì›ì²œ ì§€í‘œ)")
    metric = st.radio("ë¬´ì—‡ìœ¼ë¡œ í•©ê³„/ì˜ˆì¸¡í• ê¹Œ?", ["íŒë§¤ëŸ‰", "íŒë§¤ê¸ˆì•¡"], horizontal=True)

    st.divider()
    st.header("ğŸ§ª â‘¢ ì˜ˆì¸¡ ë°©ë²•")
    METHOD_CHOICES = ["ì„ í˜•ì¶”ì„¸(OLS)", "CAGR(ë³µë¦¬ì„±ì¥)", "Holt(ì§€ìˆ˜í‰í™œ)", "ì§€ìˆ˜í‰í™œ(SES)"]
    methods = st.multiselect("ë°©ë²• ì„ íƒ(ì •ë ¬ ê¸°ì¤€ì€ ì²« ë²ˆì§¸)", METHOD_CHOICES, default=METHOD_CHOICES)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _clean_col(s: str) -> str:
    return re.sub(r"\s+", "", str(s)).strip()

def _extract_year_from_filename(name: str) -> int | None:
    m = re.search(r"(19|20)(\d{2})(\d{2})?$", name.replace(".xlsx",""))
    return int(m.group(1)+m.group(2)) if m else None

def _parse_year_series(s: pd.Series) -> pd.Series:
    if s is None:
        return pd.Series([pd.NA]*0, dtype="Int64")
    x = s.astype(str).str.strip()
    y = pd.to_datetime(x, errors="coerce", infer_datetime_format=True)
    if y.isna().all():
        y = pd.to_datetime(x, format="%b-%y", errors="coerce")
    out = y.dt.year.astype("Int64")
    m2 = out.isna() & x.str.fullmatch(r"\d{2}")
    out.loc[m2] = 2000 + x.loc[m2].astype(int)
    m4 = out.isna() & x.str.fullmatch(r"(19|20)\d{2}")
    out.loc[m4] = x.loc[m4].astype(int)
    return out

def _coerce_num(s): return pd.to_numeric(s, errors="coerce")

@st.cache_data(show_spinner=False)
def load_and_prepare(files, repo_use: bool, metric_key: str):
    """
    ì—¬ëŸ¬ ì—‘ì…€ ì½ì–´ â€˜ì‚°ì—…ìš©â€™ë§Œ í•„í„° â†’ (ì—…ì¢…, ì—°ë„, ê°’) Long ë°˜í™˜.
    metric_key: 'íŒë§¤ëŸ‰' ë˜ëŠ” 'íŒë§¤ê¸ˆì•¡'
    """
    targets = []
    if files:
        for f in files:
            targets.append((f.name, f))
    elif repo_use:
        for p in sorted([p for p in Path(".").glob("ì‚°ì—…ìš©_*.xlsx")]):
            targets.append((p.name, p))
    if not targets:
        return pd.DataFrame(columns=["ì—…ì¢…","ì—°ë„","ê°’"]), [], {}

    frames, loaded_names = [], []
    perfile_sum = {}

    for name, src in targets:
        df = pd.read_excel(src, engine="openpyxl")
        df.columns = [_clean_col(c) for c in df.columns]

        # í›„ë³´ íƒìƒ‰
        cand_item = [c for c in df.columns if "ìƒí’ˆëª…" in c]
        cand_ind  = [c for c in df.columns if c.startswith("ì—…ì¢…")]
        if metric_key == "íŒë§¤ê¸ˆì•¡":
            cand_val = [c for c in df.columns if ("íŒë§¤ê¸ˆì•¡" in c or "ê¸ˆì•¡" in c or "ìš”ê¸ˆ" in c or "ë§¤ì¶œ" in c)]
        else:  # íŒë§¤ëŸ‰
            cand_val = [c for c in df.columns if ("íŒë§¤ëŸ‰" in c or "ì‚¬ìš©ëŸ‰" in c or "ìˆ˜ëŸ‰" in c or c.endswith("ëŸ‰"))]
        cand_ym   = [c for c in df.columns if c in ("íŒë§¤ë…„ì›”","ë…„ì›”","ì›”","ì—°ë„","ë…„ë„")]

        if not cand_item or not cand_ind or not cand_val:
            continue

        col_item, col_ind, col_val = cand_item[0], cand_ind[0], cand_val[0]
        col_ym = cand_ym[0] if cand_ym else None

        # ì‚°ì—…ìš©ë§Œ
        d = df.loc[df[col_item].astype(str).str.contains("ì‚°ì—…ìš©", na=False),
                   [col_ind, col_val] + ([col_ym] if col_ym else [])].copy()
        d[col_val] = _coerce_num(d[col_val])

        # ì—°ë„ ì¶”ì¶œ(íŒë§¤ë…„ì›” ìš°ì„ , ì‹¤íŒ¨ì‹œ íŒŒì¼ëª…)
        yy = _parse_year_series(d[col_ym]) if col_ym else pd.Series([pd.NA]*len(d), dtype="Int64")
        if yy.isna().all():
            fn_year = _extract_year_from_filename(name)
            if fn_year is not None:
                yy = pd.Series([fn_year]*len(d), dtype="Int64")
        d["ì—°ë„"] = yy.astype("Int64")

        d = d.rename(columns={col_ind: "ì—…ì¢…", col_val: "ê°’"})
        d = d.dropna(subset=["ì—…ì¢…","ê°’","ì—°ë„"])
        d["ì—°ë„"] = d["ì—°ë„"].astype(int)

        frames.append(d[["ì—…ì¢…","ì—°ë„","ê°’"]])
        loaded_names.append(name)
        perfile_sum[name] = float(d["ê°’"].sum())

    if not frames:
        return pd.DataFrame(columns=["ì—…ì¢…","ì—°ë„","ê°’"]), loaded_names, perfile_sum

    longdf = pd.concat(frames, ignore_index=True)

    agg = (longdf.groupby(["ì—…ì¢…","ì—°ë„"], as_index=False)["ê°’"]
           .sum()
           .sort_values(["ì—°ë„","ê°’"], ascending=[True, False]))
    return agg, loaded_names, perfile_sum

def _ols(x, y, targets):
    coef = np.polyfit(x, y, 1)
    return [float(np.polyval(coef, t)) for t in targets], np.polyval(coef, x)

def _cagr(x, y, targets):
    y0, yT = float(y[0]), float(y[-1]); n = int(x[-1] - x[0])
    if y0 <= 0 or yT <= 0 or n <= 0: return _ols(x, y, targets)
    g = (yT / y0) ** (1.0 / n) - 1.0
    last = x[-1]
    return [float(yT * (1.0 + g) ** (t - last)) for t in targets], np.array(y, dtype=float)

def _holt(y, last_train_year, targets):
    x_years = list(range(last_train_year - len(y) + 1, last_train_year + 1))
    if Holt is None or len(y) < 2 or any(t <= last_train_year for t in targets): return _ols(x_years, y, targets)
    fit = Holt(np.asarray(y), exponential=False, damped_trend=False, initialization_method="estimated").fit(optimized=True)
    hmax = max(t - last_train_year for t in targets); fc = fit.forecast(hmax)
    return [float(fc[h - 1]) for h in [t - last_train_year for t in targets]], np.array(fit.fittedvalues, dtype=float)

def _ses(y, last_train_year, targets):
    x_years = list(range(last_train_year - len(y) + 1, last_train_year + 1))
    if SimpleExpSmoothing is None or len(y) < 2 or any(t <= last_train_year for t in targets): return _ols(x_years, y, targets)
    fit = SimpleExpSmoothing(np.asarray(y)).fit(optimized=True)
    hmax = max(t - last_train_year for t in targets); fc = fit.forecast(hmax)
    return [float(fc[h - 1]) for h in [t - last_train_year for t in targets]], np.array(fit.fittedvalues, dtype=float)

def fmt_int(x):
    if pd.isna(x): return ""
    try: return f"{int(round(float(x))):,}"
    except Exception: return x

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_long_ui, loaded_names, perfile_sum = load_and_prepare(ups, use_repo, metric)

if df_long_ui.empty:
    st.info("ì¢Œì¸¡ì—ì„œ ì—°ë„ë³„ ì—‘ì…€ì„ ì˜¬ë¦¬ê±°ë‚˜ â€˜Repo íŒŒì¼ ìë™ ì½ê¸°â€™ë¥¼ ì¼œì¤˜.")
else:
    st.success(f"ë¡œë“œ ì™„ë£Œ: ì—…ì¢… {df_long_ui['ì—…ì¢…'].nunique():,}ê°œ, ì—°ë„ ë²”ìœ„ {df_long_ui['ì—°ë„'].min()}â€“{df_long_ui['ì—°ë„'].max()} Â· ì§‘ê³„ëŒ€ìƒ: **{metric}**")

# ğŸ” ì›ì²œ ì§„ë‹¨(ì—°ë„ë³„ í•©ê³„ + íŒŒì¼ë³„ í•©ê³„)
if not df_long_ui.empty:
    with st.expander("ğŸ” ì›ì²œ ì§„ë‹¨(ì—°ë„ë³„ í•©ê³„ & íŒŒì¼ ë¡œë”© í™•ì¸)", expanded=False):
        yr_tot = df_long_ui.groupby("ì—°ë„", as_index=False)["ê°’"].sum().sort_values("ì—°ë„")
        yr_tot_disp = yr_tot.copy(); yr_tot_disp["ê°’"] = yr_tot_disp["ê°’"].apply(fmt_int)
        st.write("ì—°ë„ë³„ ì›ì²œ í•©ê³„(ì‚°ì—…ìš©Â·ì„ íƒì§€í‘œ):")
        st.dataframe(yr_tot_disp, use_container_width=True)
        if loaded_names:
            st.write("íŒŒì¼ë³„ ë¡œë”© í•©ê³„(í•„í„° í›„):")
            pf = pd.DataFrame({"íŒŒì¼ëª…": loaded_names, "í•©ê³„": [perfile_sum[n] for n in loaded_names]})
            pf["í•©ê³„"] = pf["í•©ê³„"].apply(fmt_int)
            st.dataframe(pf, use_container_width=True)

# UI: í•™ìŠµ/ì˜ˆì¸¡ ê¸°ê°„
TRAIN_YEARS = []
FORECAST_YEARS = []
run_clicked = False
if not df_long_ui.empty:
    years = sorted(df_long_ui["ì—°ë„"].unique().tolist())
    default_train = years[-5:] if len(years) >= 5 else years
    with st.sidebar:
        st.divider()
        st.header("ğŸ—“ï¸ â‘£ í•™ìŠµ/ì˜ˆì¸¡ ê¸°ê°„")
        TRAIN_YEARS = st.multiselect("í•™ìŠµ ì—°ë„", years, default=default_train)
        TRAIN_YEARS = sorted(TRAIN_YEARS) if TRAIN_YEARS else []
        future = list(range(years[-1], years[-1] + 10))
        yr_opts = sorted(set(years + future))
        start_y = st.selectbox("ì˜ˆì¸¡ ì‹œì‘(ì—°)", yr_opts, index=yr_opts.index(years[-1]))
        end_y   = st.selectbox("ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", yr_opts, index=min(len(yr_opts)-1, yr_opts.index(years[-1])+1))
        FORECAST_YEARS = list(range(min(start_y, end_y), max(start_y, end_y) + 1))
        st.divider()
        run_clicked = st.button("ğŸš€ ì˜ˆì¸¡ ì‹œì‘", use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒíƒœ ìœ ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "started" not in st.session_state: st.session_state.started = False
if "store" not in st.session_state:   st.session_state.store = {}

def compute_and_store():
    pv_all = df_long_ui.pivot_table(index="ì—…ì¢…", columns="ì—°ë„", values="ê°’", aggfunc="sum").fillna(0)
    missing = [y for y in TRAIN_YEARS if y not in pv_all.columns]
    if missing:
        st.error(f"í•™ìŠµ ì—°ë„ ë°ì´í„° ì—†ìŒ: {missing}")
        st.stop()
    pv = pv_all.reindex(columns=TRAIN_YEARS).fillna(0)

    result = pv.copy(); result.columns = [f"{c} ì‹¤ì " for c in result.columns]

    for ind, row in pv.iterrows():
        y = row.values.astype(float).tolist(); x = TRAIN_YEARS; last = x[-1]
        for m in methods:
            label = str(m)
            if "OLS" in label:   preds, _ = _ols(x, y, FORECAST_YEARS)
            elif "CAGR" in label: preds, _ = _cagr(x, y, FORECAST_YEARS)
            elif "Holt" in label: preds, _ = _holt(y, last, FORECAST_YEARS)
            elif "SES" in label:  preds, _ = _ses(y, last, FORECAST_YEARS)
            else:                 preds, _ = _ols(x, y, FORECAST_YEARS)
            for yy, p in zip(FORECAST_YEARS, preds):
                col = f"{label}({yy})"
                if col not in result.columns: result[col] = np.nan
                result.loc[ind, col] = p

    sort_method = methods[0]
    sort_col = f"{sort_method}({FORECAST_YEARS[-1]})"
    if sort_col not in result.columns:
        alt_cols = [c for c in result.columns if c.endswith(f"({FORECAST_YEARS[-1]})")]
        sort_col = alt_cols[0] if alt_cols else result.columns[-1]
    final_sorted = result.sort_values(by=sort_col, ascending=False); final_sorted.index.name = "ì—…ì¢…"

    totals = final_sorted.sum(axis=0, numeric_only=True)
    total_row = pd.DataFrame([totals.to_dict()], index=["ì´í•©"])
    final_with_total = pd.concat([final_sorted, total_row], axis=0)

    st.session_state.store = dict(
        pv=pv, final=final_sorted, final_total=final_with_total,
        train_years=TRAIN_YEARS, fc_years=FORECAST_YEARS, methods=methods
    )
    st.session_state.started = True

if run_clicked and not df_long_ui.empty and methods and TRAIN_YEARS and FORECAST_YEARS:
    compute_and_store()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²°ê³¼ í‘œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.started:
    pv = st.session_state.store["pv"]
    final_sorted = st.session_state.store["final"]
    final_total  = st.session_state.store["final_total"]
    TRAIN_YEARS  = st.session_state.store["train_years"]
    FORECAST_YEARS = st.session_state.store["fc_years"]
    methods = st.session_state.store["methods"]

    st.success(f"ì—…ì¢… {pv.shape[0]}ê°œ, í•™ìŠµ {TRAIN_YEARS[0]}â€“{TRAIN_YEARS[-1]}, ì˜ˆì¸¡ {FORECAST_YEARS[0]}â€“{FORECAST_YEARS[-1]} Â· ì§€í‘œ: {metric}")

    st.subheader("ğŸ§¾ ì—…ì¢…ë³„ ì˜ˆì¸¡ í‘œ")
    disp = final_total.copy(); disp.insert(0, "ì—…ì¢…", disp.index)
    for c in disp.columns[1:]: disp[c] = disp[c].apply(fmt_int)
    st.dataframe(disp.reset_index(drop=True), use_container_width=True)

    st.subheader("ğŸ“ˆ ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸)")
    tot_actual = pv.sum(axis=0).reset_index(); tot_actual.columns = ["ì—°ë„", "í•©ê³„"]
    pts = []
    for m in methods:
        for yy in FORECAST_YEARS:
            col = f"{m}({yy})"
            if col in final_sorted.columns:
                pts.append({"ì—°ë„": yy, "ë°©ë²•": m, "ê°’": float(final_sorted[col].sum())})
    pts_df = pd.DataFrame(pts)

    area = alt.Chart(tot_actual).mark_area(opacity=0.25).encode(
        x=alt.X("ì—°ë„:O"), y=alt.Y("í•©ê³„:Q", axis=alt.Axis(format=",")),
        tooltip=[alt.Tooltip("ì—°ë„:O"), alt.Tooltip("í•©ê³„:Q", format=",")])
    line = alt.Chart(tot_actual).mark_line(size=3).encode(x="ì—°ë„:O", y=alt.Y("í•©ê³„:Q", axis=alt.Axis(format=",")))
    if not pts_df.empty:
        ptsch = alt.Chart(pts_df).mark_point(size=150, filled=True).encode(
            x="ì—°ë„:O", y=alt.Y("ê°’:Q", axis=alt.Axis(format=",")),
            color=alt.Color("ë°©ë²•:N"), shape=alt.Shape("ë°©ë²•:N"),
            tooltip=[alt.Tooltip("ë°©ë²•:N"), alt.Tooltip("ì—°ë„:O"), alt.Tooltip("ê°’:Q", format=",")])
        labels = ptsch.mark_text(dy=-12, fontWeight="bold").encode(text=alt.Text("ê°’:Q", format=","))
        st.altair_chart((area + line + ptsch + labels).interactive(), use_container_width=True, theme="streamlit")
    else:
        st.altair_chart((area + line).interactive(), use_container_width=True, theme="streamlit")

    st.subheader("ğŸ† ìƒìœ„ 10ê°œ ì—…ì¢… â€” ì˜ˆì¸¡ ë¹„êµ / ì‹¤ì  ì¶”ì´")
    yy_pick = st.radio("ë§‰ëŒ€ê·¸ë˜í”„ ê¸°ì¤€ ì˜ˆì¸¡ì—°ë„", FORECAST_YEARS, index=len(FORECAST_YEARS)-1, horizontal=True, key="yy_pick")
    method_cols = [f"{m}({yy_pick})" for m in methods if f"{m}({yy_pick})" in final_sorted.columns]
    if method_cols:
        top10 = final_sorted.head(10).index.tolist()
        bar_base = final_sorted.loc[top10, method_cols].copy(); bar_base.index.name = "ì—…ì¢…"
        pred_long = bar_base.reset_index().melt(id_vars="ì—…ì¢…", var_name="ë°©ë²•ì—°ë„", value_name="ì˜ˆì¸¡")
        pred_long["ë°©ë²•"] = pred_long["ë°©ë²•ì—°ë„"].str.replace(r"\(\d{4}\)$", "", regex=True)

        sel = alt.selection_point(fields=["ë°©ë²•"], bind="legend")
        bars = alt.Chart(pred_long).mark_bar().encode(
            x=alt.X("ì—…ì¢…:N", sort=top10, title=None),
            xOffset=alt.XOffset("ë°©ë²•:N"),
            y=alt.Y("ì˜ˆì¸¡:Q", axis=alt.Axis(format=","), title=f"{yy_pick} ì˜ˆì¸¡"),
            color=alt.Color("ë°©ë²•:N"), opacity=alt.condition(sel, alt.value(1.0), alt.value(0.25)),
            tooltip=[alt.Tooltip("ì—…ì¢…:N"), alt.Tooltip("ë°©ë²•:N"), alt.Tooltip("ì˜ˆì¸¡:Q", format=",")]
        ).add_params(sel).properties(height=420)
        bar_txt = bars.mark_text(dy=-5, fontSize=10).encode(text=alt.Text("ì˜ˆì¸¡:Q", format=","))

        st.markdown("â€» ë¼ì¸ ê·¸ë˜í”„ëŠ” **ì²« ë²ˆì§¸ë¡œ ì„ íƒí•œ ë°©ë²•**ìœ¼ë¡œ ì˜ˆì¸¡ì—°ë„ë¥¼ ì´ì–´ì„œ ë³´ì—¬ì¤˜.")
        method_for_line = methods[0]
        pred_cols_for_line = [f"{method_for_line}({yy})" for yy in FORECAST_YEARS if f"{method_for_line}({yy})" in final_sorted.columns]

        actual_long = pv.loc[top10, TRAIN_YEARS].reset_index().melt(id_vars="ì—…ì¢…", var_name="ì—°ë„", value_name="ê°’")
        actual_long["ì¶œì²˜"] = "ì‹¤ì "

        pred_line = pd.DataFrame()
        if pred_cols_for_line:
            pred_line = final_sorted.loc[top10, pred_cols_for_line].copy()
            pred_line.columns = [int(re.search(r"\((\d{4})\)", c).group(1)) for c in pred_line.columns]
            pred_line = pred_line.reset_index().melt(id_vars="ì—…ì¢…", var_name="ì—°ë„", value_name="ê°’")
            pred_line["ì¶œì²˜"] = f"ì˜ˆì¸¡({method_for_line})"

        line_df = pd.concat([actual_long, pred_line], ignore_index=True)
        year_order = TRAIN_YEARS + [y for y in FORECAST_YEARS if y not in TRAIN_YEARS]
        line_df["ì—°ë„"] = pd.Categorical(line_df["ì—°ë„"].astype(str), categories=[str(y) for y in year_order], ordered=True)

        c1, c2 = st.columns(2)
        with c1: st.altair_chart((bars + bar_txt).interactive(), use_container_width=True, theme="streamlit")
        with c2:
            sel2 = alt.selection_point(fields=["ì—…ì¢…"], bind="legend")
            lines = alt.Chart(line_df).mark_line(point=True, strokeWidth=3).encode(
                x=alt.X("ì—°ë„:O", title=None), y=alt.Y("ê°’:Q", axis=alt.Axis(format=",")),
                color=alt.Color("ì—…ì¢…:N", sort=top10, legend=alt.Legend(title="ì—…ì¢…(í´ë¦­ìœ¼ë¡œ ê°•ì¡°)")),
                opacity=alt.condition(sel2, alt.value(1.0), alt.value(0.25)),
                tooltip=[alt.Tooltip("ì—…ì¢…:N"), alt.Tooltip("ì—°ë„:O"), alt.Tooltip("ê°’:Q", format=","), alt.Tooltip("ì¶œì²˜:N")]
            ).add_params(sel2).properties(height=420)
            st.altair_chart(lines.interactive(), use_container_width=True, theme="streamlit")
    else:
        st.info(f"{yy_pick}ë…„ ì˜ˆì¸¡ ì—´ì´ ì—†ì–´ì„œ ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ìƒëµí–ˆì–´.")

    st.subheader("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    out_all = final_total.copy(); out_all.insert(0, "ì—…ì¢…", out_all.index)
    fname = f"industry_forecast_{FORECAST_YEARS[0]}-{FORECAST_YEARS[-1]}_{metric}.xlsx"

    wb = Workbook(); wb.remove(wb.active)
    ws_all = wb.create_sheet("ì „ì²´")
    for r in dataframe_to_rows(out_all, index=False, header=True): ws_all.append(r)

    def add_method_sheet(mth):
        ws = wb.create_sheet(mth)
        dfm = pv.copy(); dfm.columns = [f"{c} ì‹¤ì " for c in dfm.columns]
        pred_cols = [f"{mth}({yy})" for yy in FORECAST_YEARS if f"{mth}({yy})" in final_sorted.columns]
        for c in pred_cols: dfm[c] = final_sorted[c]
        order_col = pred_cols[-1] if pred_cols else dfm.columns[-1]
        dfm = dfm.sort_values(by=order_col, ascending=False).reset_index().rename(columns={"index":"ì—…ì¢…"})
        for r in dataframe_to_rows(dfm, index=False, header=True): ws.append(r)

        if pred_cols:
            topN = min(20, len(dfm)); y = FORECAST_YEARS[-1]; use_col = f"{mth}({y})"
            sc = dfm.shape[1] + 2
            ws.cell(row=1, column=sc, value="ì—…ì¢…"); ws.cell(row=1, column=sc+1, value=f"{y} ì˜ˆì¸¡")
            for i in range(topN):
                ws.cell(row=i+2, column=sc, value=dfm.loc[i, "ì—…ì¢…"])
                v = dfm.loc[i, use_col]; ws.cell(row=i+2, column=sc+1, value=float(v if pd.notna(v) else 0))
            bar = BarChart(); bar.title = f"Top-20 {y} ({mth})"
            data = Reference(ws, min_col=sc+1, min_row=1, max_row=topN+1)
            cats = Reference(ws, min_col=sc,   min_row=2, max_row=topN+1)
            bar.add_data(data, titles_from_data=True); bar.set_categories(cats)
            bar.y_axis.number_format = '#,##0'; ws.add_chart(bar, ws.cell(row=2, column=sc+3).coordinate)

        la = dfm.shape[1] + 8
        ws.cell(row=1, column=la,   value="ì—°ë„"); ws.cell(row=1, column=la+1, value="ì´í•©")
        for i, yv in enumerate(TRAIN_YEARS, start=2):
            ws.cell(row=i, column=la,   value=yv); ws.cell(row=i, column=la+1, value=float(pv[yv].sum()))
        base = len(TRAIN_YEARS) + 2
        for j, yv in enumerate(FORECAST_YEARS):
            ws.cell(row=base+j, column=la,   value=yv)
            col = f"{mth}({yv})"; tot = float(final_sorted[col].sum()) if col in final_sorted.columns else 0.0
            ws.cell(row=base+j, column=la+1, value=tot)
        lch = LineChart(); lch.title = f"ì—°ë„ë³„ ì´í•©(ì‹¤ì +ì˜ˆì¸¡, {mth})"
        mr = base + len(FORECAST_YEARS) - 1
        d = Reference(ws, min_col=la+1, min_row=1, max_row=mr)
        c = Reference(ws, min_col=la,   min_row=2, max_row=mr)
        lch.add_data(d, titles_from_data=True); lch.set_categories(c)
        lch.y_axis.number_format = '#,##0'; ws.add_chart(lch, ws.cell(row=2, column=la+3).coordinate)

    for m in methods: add_method_sheet(m)

    bio = BytesIO(); wb.save(bio)
    st.download_button("ì—‘ì…€(xlsx) ë‹¤ìš´ë¡œë“œ", bio.getvalue(), file_name=fname,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    st.download_button(
        "ì—…ì¢…ë³„ ì˜ˆì¸¡í‘œ CSV ë‹¤ìš´ë¡œë“œ",
        out_all.to_csv(index=False).encode("utf-8-sig"),
        file_name=fname.replace(".xlsx",".csv"),
        mime="text/csv"
    )
